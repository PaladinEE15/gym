{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for DDPG-mountain\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.ddpg.policies import MlpPolicy\n",
    "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
    "from stable_baselines import DDPG\n",
    "\n",
    "env = gym.make('NoisyMountainCarContinuous-v0')\n",
    "\n",
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "param_noise = None\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(MlpPolicy, env, verbose=1, param_noise=param_noise, action_noise=action_noise,memory_limit=5000,tensorboard_log='D:/DDPG_mountain_Logs')\n",
    "model.learn(total_timesteps=30000)\n",
    "#should be 30w steps\n",
    "model.save(\"ddpg_mountain\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpg_mountain\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#this is for DDPG-pendulum\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.ddpg.policies import MlpPolicy\n",
    "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
    "from stable_baselines import DDPG\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "\n",
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "param_noise = None\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(MlpPolicy, env, verbose=1, param_noise=param_noise, action_noise=action_noise,memory_limit=50000,tensorboard_log='D:/DDPG_pendulum_Logs')\n",
    "model.learn(total_timesteps=200000)\n",
    "model.save(\"ddpg_pendulum\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpg_pendulum\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#this is for SAC-pendulum\n",
    "#first experiment:gamma=0.99,0.95,0.90,0.85,1\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines import SAC\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,tensorboard_log='D:\\Logs',gamma=0.99, learning_rate=0.0003)\n",
    "model.learn(total_timesteps=30000, log_interval=10)\n",
    "#model.save(\"sac_noisypendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,tensorboard_log='D:\\Logs',gamma=0.99, learning_rate=0.001)\n",
    "model.learn(total_timesteps=30000, log_interval=10)\n",
    "#model.save(\"sac_noisypendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,tensorboard_log='D:\\Logs',gamma=0.99, learning_rate=0.003)\n",
    "model.learn(total_timesteps=30000, log_interval=10)\n",
    "#model.save(\"sac_noisypendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,tensorboard_log='D:\\Logs',gamma=0.99, learning_rate=0.0001)\n",
    "model.learn(total_timesteps=30000, log_interval=10)\n",
    "#model.save(\"sac_noisypendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,tensorboard_log='D:\\Logs',gamma=0.99, learning_rate=0.00003)\n",
    "model.learn(total_timesteps=30000, log_interval=10)\n",
    "#model.save(\"sac_noisypendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "print('finish!')\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "model = SAC.load(\"sac_noisypendulum\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for SAC-mountain\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines import SAC\n",
    "\n",
    "env = gym.make('NoiseMountainCarContinuous-v0')\n",
    "\n",
    "model = SAC(MlpPolicy, env, verbose=1,learning_starts=0,learning_rate=0.0003,buffer_size=50000,batch_size=64,ent_coef='auto',train_freq=1,gradient_steps=1,tensorboard_log='D:/SAC_mountain_Logs')\n",
    "model.learn(total_timesteps=60000, log_interval=10)\n",
    "model.save(\"sac_noisymountaion\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = SAC.load(\"sac_noisymountaion\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n| total/steps             | 79998    |\n| total/steps_per_second  | 387      |\n| train/loss_actor        | -5.07    |\n| train/loss_critic       | 0.192    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 3.98     |\n| reference_Q_std         | 14.4     |\n| reference_action_mean   | 0.0545   |\n| reference_action_std    | 0.284    |\n| reference_actor_Q_mean  | 4.03     |\n| reference_actor_Q_std   | 14.4     |\n| rollout/Q_mean          | 1.22     |\n| rollout/actions_mean    | -0.00597 |\n| rollout/actions_std     | 0.603    |\n| rollout/episode_steps   | 795      |\n| rollout/episodes        | 113      |\n| rollout/return          | 12.7     |\n| rollout/return_history  | 15.7     |\n| total/duration          | 232      |\n| total/episodes          | 113      |\n| total/epochs            | 1        |\n| total/steps             | 89998    |\n| total/steps_per_second  | 388      |\n| train/loss_actor        | -8.18    |\n| train/loss_critic       | 0.445    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 4.46     |\n| reference_Q_std         | 16.1     |\n| reference_action_mean   | 0.329    |\n| reference_action_std    | 0.607    |\n| reference_actor_Q_mean  | 4.75     |\n| reference_actor_Q_std   | 16.6     |\n| rollout/Q_mean          | 2.06     |\n| rollout/actions_mean    | 0.0142   |\n| rollout/actions_std     | 0.607    |\n| rollout/episode_steps   | 718      |\n| rollout/episodes        | 139      |\n| rollout/return          | 26       |\n| rollout/return_history  | 43.6     |\n| total/duration          | 258      |\n| total/episodes          | 139      |\n| total/epochs            | 1        |\n| total/steps             | 99998    |\n| total/steps_per_second  | 388      |\n| train/loss_actor        | -9.94    |\n| train/loss_critic       | 0.489    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 6.18     |\n| reference_Q_std         | 17.7     |\n| reference_action_mean   | -0.0904  |\n| reference_action_std    | 0.766    |\n| reference_actor_Q_mean  | 7.15     |\n| reference_actor_Q_std   | 18.8     |\n| rollout/Q_mean          | 3.29     |\n| rollout/actions_mean    | 0.0185   |\n| rollout/actions_std     | 0.621    |\n| rollout/episode_steps   | 625      |\n| rollout/episodes        | 176      |\n| rollout/return          | 36.7     |\n| rollout/return_history  | 69.9     |\n| total/duration          | 284      |\n| total/episodes          | 176      |\n| total/epochs            | 1        |\n| total/steps             | 109998   |\n| total/steps_per_second  | 388      |\n| train/loss_actor        | -25.2    |\n| train/loss_critic       | 2.24     |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 11.1     |\n| reference_Q_std         | 22.7     |\n| reference_action_mean   | -0.102   |\n| reference_action_std    | 0.952    |\n| reference_actor_Q_mean  | 13.3     |\n| reference_actor_Q_std   | 24.1     |\n| rollout/Q_mean          | 6.3      |\n| rollout/actions_mean    | 0.0097   |\n| rollout/actions_std     | 0.646    |\n| rollout/episode_steps   | 427      |\n| rollout/episodes        | 281      |\n| rollout/return          | 56.9     |\n| rollout/return_history  | 90.6     |\n| total/duration          | 310      |\n| total/episodes          | 281      |\n| total/epochs            | 1        |\n| total/steps             | 119998   |\n| total/steps_per_second  | 388      |\n| train/loss_actor        | -43      |\n| train/loss_critic       | 2.76     |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 16.1     |\n| reference_Q_std         | 27.2     |\n| reference_action_mean   | 0.102    |\n| reference_action_std    | 0.935    |\n| reference_actor_Q_mean  | 17.9     |\n| reference_actor_Q_std   | 27.9     |\n| rollout/Q_mean          | 9.16     |\n| rollout/actions_mean    | 0.0214   |\n| rollout/actions_std     | 0.666    |\n| rollout/episode_steps   | 339      |\n| rollout/episodes        | 383      |\n| rollout/return          | 66.1     |\n| rollout/return_history  | 91.4     |\n| total/duration          | 336      |\n| total/episodes          | 383      |\n| total/epochs            | 1        |\n| total/steps             | 129998   |\n| total/steps_per_second  | 387      |\n| train/loss_actor        | -43.3    |\n| train/loss_critic       | 4.69     |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 19.4     |\n| reference_Q_std         | 29.1     |\n| reference_action_mean   | 0.0593   |\n| reference_action_std    | 0.971    |\n| reference_actor_Q_mean  | 21.2     |\n| reference_actor_Q_std   | 28.3     |\n| rollout/Q_mean          | 11.8     |\n| rollout/actions_mean    | 0.041    |\n| rollout/actions_std     | 0.682    |\n| rollout/episode_steps   | 286      |\n| rollout/episodes        | 489      |\n| rollout/return          | 71.9     |\n| rollout/return_history  | 92.8     |\n| total/duration          | 363      |\n| total/episodes          | 489      |\n| total/epochs            | 1        |\n| total/steps             | 139998   |\n| total/steps_per_second  | 386      |\n| train/loss_actor        | -46.2    |\n| train/loss_critic       | 2.2      |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 21.1     |\n| reference_Q_std         | 28.8     |\n| reference_action_mean   | -0.11    |\n| reference_action_std    | 0.962    |\n| reference_actor_Q_mean  | 23.6     |\n| reference_actor_Q_std   | 27.6     |\n| rollout/Q_mean          | 14       |\n| rollout/actions_mean    | 0.0581   |\n| rollout/actions_std     | 0.694    |\n| rollout/episode_steps   | 263      |\n| rollout/episodes        | 569      |\n| rollout/return          | 74.6     |\n| rollout/return_history  | 91.3     |\n| total/duration          | 390      |\n| total/episodes          | 569      |\n| total/epochs            | 1        |\n| total/steps             | 149998   |\n| total/steps_per_second  | 385      |\n| train/loss_actor        | -43.6    |\n| train/loss_critic       | 0.82     |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 23.6     |\n| reference_Q_std         | 29.7     |\n| reference_action_mean   | -0.528   |\n| reference_action_std    | 0.834    |\n| reference_actor_Q_mean  | 27.8     |\n| reference_actor_Q_std   | 27.7     |\n| rollout/Q_mean          | 17.1     |\n| rollout/actions_mean    | 0.065    |\n| rollout/actions_std     | 0.705    |\n| rollout/episode_steps   | 234      |\n| rollout/episodes        | 685      |\n| rollout/return          | 77.8     |\n| rollout/return_history  | 93.8     |\n| total/duration          | 417      |\n| total/episodes          | 685      |\n| total/epochs            | 1        |\n| total/steps             | 159998   |\n| total/steps_per_second  | 384      |\n| train/loss_actor        | -66.5    |\n| train/loss_critic       | 0.4      |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 29       |\n| reference_Q_std         | 29.2     |\n| reference_action_mean   | -0.477   |\n| reference_action_std    | 0.864    |\n| reference_actor_Q_mean  | 34.4     |\n| reference_actor_Q_std   | 26.1     |\n| rollout/Q_mean          | 20.1     |\n| rollout/actions_mean    | 0.0595   |\n| rollout/actions_std     | 0.716    |\n| rollout/episode_steps   | 215      |\n| rollout/episodes        | 790      |\n| rollout/return          | 79.7     |\n| rollout/return_history  | 91.8     |\n| total/duration          | 444      |\n| total/episodes          | 790      |\n| total/epochs            | 1        |\n| total/steps             | 169998   |\n| total/steps_per_second  | 383      |\n| train/loss_actor        | -68.1    |\n| train/loss_critic       | 0.934    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 37.9     |\n| reference_Q_std         | 25.8     |\n| reference_action_mean   | -0.476   |\n| reference_action_std    | 0.865    |\n| reference_actor_Q_mean  | 43.8     |\n| reference_actor_Q_std   | 21.9     |\n| rollout/Q_mean          | 22.9     |\n| rollout/actions_mean    | 0.0634   |\n| rollout/actions_std     | 0.725    |\n| rollout/episode_steps   | 197      |\n| rollout/episodes        | 914      |\n| rollout/return          | 81.6     |\n| rollout/return_history  | 93.9     |\n| total/duration          | 471      |\n| total/episodes          | 914      |\n| total/epochs            | 1        |\n| total/steps             | 179998   |\n| total/steps_per_second  | 383      |\n| train/loss_actor        | -72.2    |\n| train/loss_critic       | 0.506    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 44.5     |\n| reference_Q_std         | 20.7     |\n| reference_action_mean   | -0.523   |\n| reference_action_std    | 0.825    |\n| reference_actor_Q_mean  | 50.6     |\n| reference_actor_Q_std   | 16.8     |\n| rollout/Q_mean          | 25.6     |\n| rollout/actions_mean    | 0.0613   |\n| rollout/actions_std     | 0.733    |\n| rollout/episode_steps   | 185      |\n| rollout/episodes        | 1.03e+03 |\n| rollout/return          | 82.9     |\n| rollout/return_history  | 93.3     |\n| total/duration          | 498      |\n| total/episodes          | 1.03e+03 |\n| total/epochs            | 1        |\n| total/steps             | 189998   |\n| total/steps_per_second  | 382      |\n| train/loss_actor        | -73.7    |\n| train/loss_critic       | 0.379    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 49.6     |\n| reference_Q_std         | 16.3     |\n| reference_action_mean   | -0.563   |\n| reference_action_std    | 0.825    |\n| reference_actor_Q_mean  | 56.4     |\n| reference_actor_Q_std   | 12       |\n| rollout/Q_mean          | 28       |\n| rollout/actions_mean    | 0.0558   |\n| rollout/actions_std     | 0.741    |\n| rollout/episode_steps   | 175      |\n| rollout/episodes        | 1.14e+03 |\n| rollout/return          | 84       |\n| rollout/return_history  | 93.5     |\n| total/duration          | 524      |\n| total/episodes          | 1.14e+03 |\n| total/epochs            | 1        |\n| total/steps             | 199998   |\n| total/steps_per_second  | 382      |\n| train/loss_actor        | -74.2    |\n| train/loss_critic       | 0.502    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 51.7     |\n| reference_Q_std         | 13.1     |\n| reference_action_mean   | -0.558   |\n| reference_action_std    | 0.822    |\n| reference_actor_Q_mean  | 58.8     |\n| reference_actor_Q_std   | 9.21     |\n| rollout/Q_mean          | 30.2     |\n| rollout/actions_mean    | 0.0531   |\n| rollout/actions_std     | 0.747    |\n| rollout/episode_steps   | 167      |\n| rollout/episodes        | 1.26e+03 |\n| rollout/return          | 84.8     |\n| rollout/return_history  | 93.4     |\n| total/duration          | 553      |\n| total/episodes          | 1.26e+03 |\n| total/epochs            | 1        |\n| total/steps             | 209998   |\n| total/steps_per_second  | 380      |\n| train/loss_actor        | -73.3    |\n| train/loss_critic       | 0.358    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 54.6     |\n| reference_Q_std         | 10.8     |\n| reference_action_mean   | -0.597   |\n| reference_action_std    | 0.783    |\n| reference_actor_Q_mean  | 59.3     |\n| reference_actor_Q_std   | 8.14     |\n| rollout/Q_mean          | 32.1     |\n| rollout/actions_mean    | 0.0482   |\n| rollout/actions_std     | 0.754    |\n| rollout/episode_steps   | 161      |\n| rollout/episodes        | 1.36e+03 |\n| rollout/return          | 85.5     |\n| rollout/return_history  | 92.9     |\n| total/duration          | 581      |\n| total/episodes          | 1.36e+03 |\n| total/epochs            | 1        |\n| total/steps             | 219998   |\n| total/steps_per_second  | 378      |\n| train/loss_actor        | -71.3    |\n| train/loss_critic       | 0.247    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 55.9     |\n| reference_Q_std         | 8.88     |\n| reference_action_mean   | -0.446   |\n| reference_action_std    | 0.872    |\n| reference_actor_Q_mean  | 58.4     |\n| reference_actor_Q_std   | 7.8      |\n| rollout/Q_mean          | 33.8     |\n| rollout/actions_mean    | 0.0412   |\n| rollout/actions_std     | 0.759    |\n| rollout/episode_steps   | 156      |\n| rollout/episodes        | 1.47e+03 |\n| rollout/return          | 86       |\n| rollout/return_history  | 93.3     |\n| total/duration          | 610      |\n| total/episodes          | 1.47e+03 |\n| total/epochs            | 1        |\n| total/steps             | 229998   |\n| total/steps_per_second  | 377      |\n| train/loss_actor        | -69.5    |\n| train/loss_critic       | 0.297    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 53.9     |\n| reference_Q_std         | 9.89     |\n| reference_action_mean   | -0.475   |\n| reference_action_std    | 0.857    |\n| reference_actor_Q_mean  | 58.3     |\n| reference_actor_Q_std   | 7.55     |\n| rollout/Q_mean          | 35.3     |\n| rollout/actions_mean    | 0.0377   |\n| rollout/actions_std     | 0.765    |\n| rollout/episode_steps   | 151      |\n| rollout/episodes        | 1.59e+03 |\n| rollout/return          | 86.5     |\n| rollout/return_history  | 93.3     |\n| total/duration          | 638      |\n| total/episodes          | 1.59e+03 |\n| total/epochs            | 1        |\n| total/steps             | 239998   |\n| total/steps_per_second  | 376      |\n| train/loss_actor        | -70.8    |\n| train/loss_critic       | 0.374    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 53.9     |\n| reference_Q_std         | 9.82     |\n| reference_action_mean   | -0.512   |\n| reference_action_std    | 0.845    |\n| reference_actor_Q_mean  | 58.1     |\n| reference_actor_Q_std   | 7.44     |\n| rollout/Q_mean          | 36.7     |\n| rollout/actions_mean    | 0.0362   |\n| rollout/actions_std     | 0.77     |\n| rollout/episode_steps   | 148      |\n| rollout/episodes        | 1.69e+03 |\n| rollout/return          | 86.8     |\n| rollout/return_history  | 91.5     |\n| total/duration          | 667      |\n| total/episodes          | 1.69e+03 |\n| total/epochs            | 1        |\n| total/steps             | 249998   |\n| total/steps_per_second  | 375      |\n| train/loss_actor        | -70.1    |\n| train/loss_critic       | 0.317    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 54       |\n| reference_Q_std         | 9.63     |\n| reference_action_mean   | -0.498   |\n| reference_action_std    | 0.853    |\n| reference_actor_Q_mean  | 58.1     |\n| reference_actor_Q_std   | 7.09     |\n| rollout/Q_mean          | 38       |\n| rollout/actions_mean    | 0.0402   |\n| rollout/actions_std     | 0.774    |\n| rollout/episode_steps   | 143      |\n| rollout/episodes        | 1.81e+03 |\n| rollout/return          | 87.3     |\n| rollout/return_history  | 93.8     |\n| total/duration          | 696      |\n| total/episodes          | 1.81e+03 |\n| total/epochs            | 1        |\n| total/steps             | 259998   |\n| total/steps_per_second  | 374      |\n| train/loss_actor        | -70.4    |\n| train/loss_critic       | 0.25     |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 53       |\n| reference_Q_std         | 9.53     |\n| reference_action_mean   | -0.531   |\n| reference_action_std    | 0.828    |\n| reference_actor_Q_mean  | 56.9     |\n| reference_actor_Q_std   | 6.95     |\n| rollout/Q_mean          | 39.2     |\n| rollout/actions_mean    | 0.0434   |\n| rollout/actions_std     | 0.778    |\n| rollout/episode_steps   | 140      |\n| rollout/episodes        | 1.93e+03 |\n| rollout/return          | 87.7     |\n| rollout/return_history  | 93.4     |\n| total/duration          | 724      |\n| total/episodes          | 1.93e+03 |\n| total/epochs            | 1        |\n| total/steps             | 269998   |\n| total/steps_per_second  | 373      |\n| train/loss_actor        | -70.3    |\n| train/loss_critic       | 0.184    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 52.3     |\n| reference_Q_std         | 10.3     |\n| reference_action_mean   | -0.476   |\n| reference_action_std    | 0.856    |\n| reference_actor_Q_mean  | 55.9     |\n| reference_actor_Q_std   | 7.89     |\n| rollout/Q_mean          | 40.3     |\n| rollout/actions_mean    | 0.0465   |\n| rollout/actions_std     | 0.781    |\n| rollout/episode_steps   | 136      |\n| rollout/episodes        | 2.05e+03 |\n| rollout/return          | 88       |\n| rollout/return_history  | 93.8     |\n| total/duration          | 753      |\n| total/episodes          | 2.05e+03 |\n| total/epochs            | 1        |\n| total/steps             | 279998   |\n| total/steps_per_second  | 372      |\n| train/loss_actor        | -70.7    |\n| train/loss_critic       | 0.165    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 51.5     |\n| reference_Q_std         | 10.9     |\n| reference_action_mean   | -0.446   |\n| reference_action_std    | 0.872    |\n| reference_actor_Q_mean  | 55.1     |\n| reference_actor_Q_std   | 8.55     |\n| rollout/Q_mean          | 41.4     |\n| rollout/actions_mean    | 0.0465   |\n| rollout/actions_std     | 0.783    |\n| rollout/episode_steps   | 135      |\n| rollout/episodes        | 2.15e+03 |\n| rollout/return          | 88.3     |\n| rollout/return_history  | 92.8     |\n| total/duration          | 781      |\n| total/episodes          | 2.15e+03 |\n| total/epochs            | 1        |\n| total/steps             | 289998   |\n| total/steps_per_second  | 371      |\n| train/loss_actor        | -69.6    |\n| train/loss_critic       | 0.239    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 51.2     |\n| reference_Q_std         | 11.2     |\n| reference_action_mean   | -0.338   |\n| reference_action_std    | 0.9      |\n| reference_actor_Q_mean  | 54.1     |\n| reference_actor_Q_std   | 9.37     |\n| rollout/Q_mean          | 42.3     |\n| rollout/actions_mean    | 0.0516   |\n| rollout/actions_std     | 0.786    |\n| rollout/episode_steps   | 132      |\n| rollout/episodes        | 2.27e+03 |\n| rollout/return          | 88.5     |\n| rollout/return_history  | 93.3     |\n| total/duration          | 810      |\n| total/episodes          | 2.27e+03 |\n| total/epochs            | 1        |\n| total/steps             | 299998   |\n| total/steps_per_second  | 370      |\n| train/loss_actor        | -69.3    |\n| train/loss_critic       | 0.254    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\nfinish!\n"
    }
   ],
   "source": [
    "#this is for four-compare\n",
    "#first experiment:gamma=0.99,0.95,0.90,0.85,1\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines import SAC, DDPG\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,gamma=0.99, learning_rate=0.0003)\n",
    "model.learn(total_timesteps=300000, log_interval=10)\n",
    "model.save(\"sac_pendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "model = SAC(MlpPolicy, env, verbose=1,learning_starts=0,learning_rate=0.0003,buffer_size=50000,batch_size=64,ent_coef='auto',train_freq=1,gradient_steps=1)\n",
    "model.learn(total_timesteps=300000, log_interval=10)\n",
    "model.save(\"sac_mountaincar\")\n",
    "del model \n",
    "del env\n",
    "\n",
    "from stable_baselines.ddpg.policies import MlpPolicy\n",
    "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "param_noise = None\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "model = DDPG(MlpPolicy, env, verbose=1, param_noise=param_noise, action_noise=action_noise,memory_limit=50000)\n",
    "model.learn(total_timesteps=300000)\n",
    "model.save(\"DDPG_pendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "param_noise = None\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "model = DDPG(MlpPolicy, env, verbose=1, param_noise=param_noise, action_noise=action_noise,memory_limit=5000)\n",
    "model.learn(total_timesteps=300000)\n",
    "model.save(\"DDPG_mountaincar\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "print('finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "et the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5845BB5C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5845BB5C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5845BB5C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E580A1A048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E580A1A048>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E580A1A048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E580A1A048>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5810721C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5810721C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5810721C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5810721C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58139C288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58139C288>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58139C288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58139C288>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E589253108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E589253108>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E589253108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E589253108>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5845CCF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5845CCF88>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5845CCF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5845CCF88>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5810721C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5810721C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5810721C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5810721C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5DAB63988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5DAB63988>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5DAB63988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5DAB63988>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58926BE48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58926BE48>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58926BE48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58926BE48>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E581385C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E581385C48>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E581385C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E581385C48>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E580B13448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E580B13448>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E580B13448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E580B13448>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E580B13448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E580B13448>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E580B13448>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E580B13448>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E586C1EB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E586C1EB08>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E586C1EB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E586C1EB08>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E581385C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E581385C48>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E581385C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E581385C48>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E583C4E0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E583C4E0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E583C4E0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E583C4E0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5DAB6C408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5DAB6C408>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5DAB6C408>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E5DAB6C408>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E581385C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E581385C48>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E581385C48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001E581385C48>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58926B0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58926B0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58926B0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58926B0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58926B0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58926B0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58926B0C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58926B0C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58055E648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58055E648>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58055E648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001E58055E648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines import SAC, DDPG\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,tensorboard_log='D:\\Compare_4',gamma=0.99, learning_rate=0.0003)\n",
    "model.learn(total_timesteps=50000, log_interval=10)\n",
    "#model.save(\"sac_noisypendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test well-trained model performance in common scenerio and noisy scenerio \n",
    "\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model=SAC.load('sac_pendulum')\n",
    "\n",
    "SACpendu_reward=[]\n",
    "for kk in range(200):\n",
    "    obs = env.reset()\n",
    "    sub_reward=[]\n",
    "    for dd in range(20):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        sub_reward.append(rewards)\n",
    "    SACpendu_reward.append(sub_reward)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittf1conda8a8c03e9f46043de9a202a9e682ce04f",
   "display_name": "Python 3.7.7 64-bit ('tf1': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}