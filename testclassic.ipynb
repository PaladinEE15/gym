{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000013D301B7BA8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000013D301B7BA8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000013D301B7BA8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000013D301B7BA8>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000013D2BEDDF60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000013D2BEDDF60>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000013D2BEDDF60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000013D2BEDDF60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n--------------------------------------\n| reference_Q_mean        | 0.207    |\n| reference_Q_std         | 0.148    |\n| reference_action_mean   | 0.014    |\n| reference_action_std    | 0.0612   |\n| reference_actor_Q_mean  | 0.25     |\n| reference_actor_Q_std   | 0.119    |\n| rollout/Q_mean          | 0.0445   |\n| rollout/actions_mean    | -0.118   |\n| rollout/actions_std     | 0.613    |\n| rollout/episode_steps   | 975      |\n| rollout/episodes        | 10       |\n| rollout/return          | -27.5    |\n| rollout/return_history  | -27.5    |\n| total/duration          | 22.6     |\n| total/episodes          | 10       |\n| total/epochs            | 1        |\n| total/steps             | 9998     |\n| total/steps_per_second  | 442      |\n| train/loss_actor        | -0.238   |\n| train/loss_critic       | 2.52     |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.169    |\n| reference_Q_std         | 0.105    |\n| reference_action_mean   | 0.0925   |\n| reference_action_std    | 0.0686   |\n| reference_actor_Q_mean  | 0.196    |\n| reference_actor_Q_std   | 0.0945   |\n| rollout/Q_mean          | 0.159    |\n| rollout/actions_mean    | 0.0882   |\n| rollout/actions_std     | 0.637    |\n| rollout/episode_steps   | 987      |\n| rollout/episodes        | 20       |\n| rollout/return          | -36.3    |\n| rollout/return_history  | -36.3    |\n| total/duration          | 45.7     |\n| total/episodes          | 20       |\n| total/epochs            | 1        |\n| total/steps             | 19998    |\n| total/steps_per_second  | 438      |\n| train/loss_actor        | -0.26    |\n| train/loss_critic       | 0.000201 |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.334    |\n| reference_Q_std         | 0.0981   |\n| reference_action_mean   | 0.0945   |\n| reference_action_std    | 0.0483   |\n| reference_actor_Q_mean  | 0.342    |\n| reference_actor_Q_std   | 0.0774   |\n| rollout/Q_mean          | 0.265    |\n| rollout/actions_mean    | 0.122    |\n| rollout/actions_std     | 0.627    |\n| rollout/episode_steps   | 972      |\n| rollout/episodes        | 30       |\n| rollout/return          | -29.7    |\n| rollout/return_history  | -29.7    |\n| total/duration          | 68.3     |\n| total/episodes          | 30       |\n| total/epochs            | 1        |\n| total/steps             | 29998    |\n| total/steps_per_second  | 439      |\n| train/loss_actor        | -0.663   |\n| train/loss_critic       | 0.295    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.294    |\n| reference_Q_std         | 0.111    |\n| reference_action_mean   | -0.0618  |\n| reference_action_std    | 0.097    |\n| reference_actor_Q_mean  | 0.323    |\n| reference_actor_Q_std   | 0.0975   |\n| rollout/Q_mean          | 0.338    |\n| rollout/actions_mean    | 0.142    |\n| rollout/actions_std     | 0.625    |\n| rollout/episode_steps   | 960      |\n| rollout/episodes        | 41       |\n| rollout/return          | -27.3    |\n| rollout/return_history  | -27.3    |\n| total/duration          | 90.8     |\n| total/episodes          | 41       |\n| total/epochs            | 1        |\n| total/steps             | 39998    |\n| total/steps_per_second  | 440      |\n| train/loss_actor        | -0.362   |\n| train/loss_critic       | 0.00042  |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.291    |\n| reference_Q_std         | 0.137    |\n| reference_action_mean   | -0.152   |\n| reference_action_std    | 0.0763   |\n| reference_actor_Q_mean  | 0.319    |\n| reference_actor_Q_std   | 0.134    |\n| rollout/Q_mean          | 0.403    |\n| rollout/actions_mean    | 0.159    |\n| rollout/actions_std     | 0.633    |\n| rollout/episode_steps   | 953      |\n| rollout/episodes        | 52       |\n| rollout/return          | -27.4    |\n| rollout/return_history  | -27.4    |\n| total/duration          | 114      |\n| total/episodes          | 52       |\n| total/epochs            | 1        |\n| total/steps             | 49998    |\n| total/steps_per_second  | 438      |\n| train/loss_actor        | -0.738   |\n| train/loss_critic       | 0.0074   |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.239    |\n| reference_Q_std         | 0.172    |\n| reference_action_mean   | 0.318    |\n| reference_action_std    | 0.12     |\n| reference_actor_Q_mean  | 0.299    |\n| reference_actor_Q_std   | 0.172    |\n| rollout/Q_mean          | 0.455    |\n| rollout/actions_mean    | 0.134    |\n| rollout/actions_std     | 0.628    |\n| rollout/episode_steps   | 950      |\n| rollout/episodes        | 63       |\n| rollout/return          | -25      |\n| rollout/return_history  | -25      |\n| total/duration          | 137      |\n| total/episodes          | 63       |\n| total/epochs            | 1        |\n| total/steps             | 59998    |\n| total/steps_per_second  | 439      |\n| train/loss_actor        | -0.641   |\n| train/loss_critic       | 0.0105   |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.231    |\n| reference_Q_std         | 0.245    |\n| reference_action_mean   | -0.0645  |\n| reference_action_std    | 0.0605   |\n| reference_actor_Q_mean  | 0.267    |\n| reference_actor_Q_std   | 0.25     |\n| rollout/Q_mean          | 0.429    |\n| rollout/actions_mean    | 0.125    |\n| rollout/actions_std     | 0.629    |\n| rollout/episode_steps   | 957      |\n| rollout/episodes        | 73       |\n| rollout/return          | -27      |\n| rollout/return_history  | -27      |\n| total/duration          | 159      |\n| total/episodes          | 73       |\n| total/epochs            | 1        |\n| total/steps             | 69998    |\n| total/steps_per_second  | 440      |\n| train/loss_actor        | -0.218   |\n| train/loss_critic       | 0.000238 |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.188    |\n| reference_Q_std         | 0.229    |\n| reference_action_mean   | 0.178    |\n| reference_action_std    | 0.144    |\n| reference_actor_Q_mean  | 0.232    |\n| reference_actor_Q_std   | 0.234    |\n| rollout/Q_mean          | 0.466    |\n| rollout/actions_mean    | 0.125    |\n| rollout/actions_std     | 0.631    |\n| rollout/episode_steps   | 955      |\n| rollout/episodes        | 83       |\n| rollout/return          | -27.7    |\n| rollout/return_history  | -27.7    |\n| total/duration          | 182      |\n| total/episodes          | 83       |\n| total/epochs            | 1        |\n| total/steps             | 79998    |\n| total/steps_per_second  | 441      |\n| train/loss_actor        | -1.05    |\n| train/loss_critic       | 0.0729   |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.165    |\n| reference_Q_std         | 0.299    |\n| reference_action_mean   | -0.0837  |\n| reference_action_std    | 0.162    |\n| reference_actor_Q_mean  | 0.2      |\n| reference_actor_Q_std   | 0.308    |\n| rollout/Q_mean          | 0.503    |\n| rollout/actions_mean    | 0.117    |\n| rollout/actions_std     | 0.636    |\n| rollout/episode_steps   | 954      |\n| rollout/episodes        | 94       |\n| rollout/return          | -27.2    |\n| rollout/return_history  | -27.2    |\n| total/duration          | 204      |\n| total/episodes          | 94       |\n| total/epochs            | 1        |\n| total/steps             | 89998    |\n| total/steps_per_second  | 441      |\n| train/loss_actor        | -0.985   |\n| train/loss_critic       | 0.0103   |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.161    |\n| reference_Q_std         | 0.55     |\n| reference_action_mean   | 0.0392   |\n| reference_action_std    | 0.207    |\n| reference_actor_Q_mean  | 0.213    |\n| reference_actor_Q_std   | 0.812    |\n| rollout/Q_mean          | 0.589    |\n| rollout/actions_mean    | 0.0784   |\n| rollout/actions_std     | 0.646    |\n| rollout/episode_steps   | 943      |\n| rollout/episodes        | 106      |\n| rollout/return          | -24      |\n| rollout/return_history  | -24      |\n| total/duration          | 227      |\n| total/episodes          | 106      |\n| total/epochs            | 1        |\n| total/steps             | 99998    |\n| total/steps_per_second  | 441      |\n| train/loss_actor        | -1.36    |\n| train/loss_critic       | 0.0545   |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.253    |\n| reference_Q_std         | 0.929    |\n| reference_action_mean   | -0.193   |\n| reference_action_std    | 0.0967   |\n| reference_actor_Q_mean  | 0.299    |\n| reference_actor_Q_std   | 1.02     |\n| rollout/Q_mean          | 0.615    |\n| rollout/actions_mean    | 0.0518   |\n| rollout/actions_std     | 0.651    |\n| rollout/episode_steps   | 938      |\n| rollout/episodes        | 117      |\n| rollout/return          | -23.8    |\n| rollout/return_history  | -21.4    |\n| total/duration          | 250      |\n| total/episodes          | 117      |\n| total/epochs            | 1        |\n| total/steps             | 109998   |\n| total/steps_per_second  | 440      |\n| train/loss_actor        | -0.267   |\n| train/loss_critic       | 0.000175 |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.248    |\n| reference_Q_std         | 0.826    |\n| reference_action_mean   | -0.242   |\n| reference_action_std    | 0.153    |\n| reference_actor_Q_mean  | 0.298    |\n| reference_actor_Q_std   | 1.05     |\n| rollout/Q_mean          | 0.585    |\n| rollout/actions_mean    | 0.0371   |\n| rollout/actions_std     | 0.645    |\n| rollout/episode_steps   | 943      |\n| rollout/episodes        | 127      |\n| rollout/return          | -24.4    |\n| rollout/return_history  | -23      |\n| total/duration          | 273      |\n| total/episodes          | 127      |\n| total/epochs            | 1        |\n| total/steps             | 119998   |\n| total/steps_per_second  | 440      |\n| train/loss_actor        | -0.209   |\n| train/loss_critic       | 0.000275 |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.271    |\n| reference_Q_std         | 0.667    |\n| reference_action_mean   | 0.122    |\n| reference_action_std    | 0.157    |\n| reference_actor_Q_mean  | 0.331    |\n| reference_actor_Q_std   | 0.977    |\n| rollout/Q_mean          | 0.557    |\n| rollout/actions_mean    | 0.0325   |\n| rollout/actions_std     | 0.648    |\n| rollout/episode_steps   | 947      |\n| rollout/episodes        | 137      |\n| rollout/return          | -26      |\n| rollout/return_history  | -26.1    |\n| total/duration          | 296      |\n| total/episodes          | 137      |\n| total/epochs            | 1        |\n| total/steps             | 129998   |\n| total/steps_per_second  | 439      |\n| train/loss_actor        | -0.265   |\n| train/loss_critic       | 0.00443  |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.317    |\n| reference_Q_std         | 0.953    |\n| reference_action_mean   | 0.254    |\n| reference_action_std    | 0.189    |\n| reference_actor_Q_mean  | 0.456    |\n| reference_actor_Q_std   | 1.38     |\n| rollout/Q_mean          | 0.545    |\n| rollout/actions_mean    | 0.0347   |\n| rollout/actions_std     | 0.648    |\n| rollout/episode_steps   | 949      |\n| rollout/episodes        | 147      |\n| rollout/return          | -26.3    |\n| rollout/return_history  | -26      |\n| total/duration          | 320      |\n| total/episodes          | 147      |\n| total/epochs            | 1        |\n| total/steps             | 139998   |\n| total/steps_per_second  | 438      |\n| train/loss_actor        | -0.121   |\n| train/loss_critic       | 0.000115 |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 0.761    |\n| reference_Q_std         | 2.68     |\n| reference_action_mean   | 0.0144   |\n| reference_action_std    | 0.413    |\n| reference_actor_Q_mean  | 1.09     |\n| reference_actor_Q_std   | 3.67     |\n| rollout/Q_mean          | 0.679    |\n| rollout/actions_mean    | 0.0451   |\n| rollout/actions_std     | 0.646    |\n| rollout/episode_steps   | 920      |\n| rollout/episodes        | 163      |\n| rollout/return          | -20.8    |\n| rollout/return_history  | -18.2    |\n| total/duration          | 343      |\n| total/episodes          | 163      |\n| total/epochs            | 1        |\n| total/steps             | 149998   |\n| total/steps_per_second  | 437      |\n| train/loss_actor        | -5.09    |\n| train/loss_critic       | 0.285    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 2.91     |\n| reference_Q_std         | 8.8      |\n| reference_action_mean   | 0.565    |\n| reference_action_std    | 0.404    |\n| reference_actor_Q_mean  | 3.61     |\n| reference_actor_Q_std   | 10.4     |\n| rollout/Q_mean          | 1.24     |\n| rollout/actions_mean    | 0.0548   |\n| rollout/actions_std     | 0.653    |\n| rollout/episode_steps   | 824      |\n| rollout/episodes        | 194      |\n| rollout/return          | -6.07    |\n| rollout/return_history  | 13.8     |\n| total/duration          | 367      |\n| total/episodes          | 194      |\n| total/epochs            | 1        |\n| total/steps             | 159998   |\n| total/steps_per_second  | 436      |\n| train/loss_actor        | -9.64    |\n| train/loss_critic       | 0.338    |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 7.45     |\n| reference_Q_std         | 16.1     |\n| reference_action_mean   | 0.998    |\n| reference_action_std    | 0.0119   |\n| reference_actor_Q_mean  | 9.02     |\n| reference_actor_Q_std   | 18.1     |\n| rollout/Q_mean          | 2.14     |\n| rollout/actions_mean    | 0.0741   |\n| rollout/actions_std     | 0.654    |\n| rollout/episode_steps   | 755      |\n| rollout/episodes        | 225      |\n| rollout/return          | 5.46     |\n| rollout/return_history  | 42.6     |\n| total/duration          | 390      |\n| total/episodes          | 225      |\n| total/epochs            | 1        |\n| total/steps             | 169998   |\n| total/steps_per_second  | 436      |\n| train/loss_actor        | -20.4    |\n| train/loss_critic       | 2.96     |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 13.9     |\n| reference_Q_std         | 22.2     |\n| reference_action_mean   | 0.569    |\n| reference_action_std    | 0.687    |\n| reference_actor_Q_mean  | 15.4     |\n| reference_actor_Q_std   | 23.8     |\n| rollout/Q_mean          | 2.82     |\n| rollout/actions_mean    | 0.0935   |\n| rollout/actions_std     | 0.657    |\n| rollout/episode_steps   | 704      |\n| rollout/episodes        | 255      |\n| rollout/return          | 12.1     |\n| rollout/return_history  | 70.8     |\n| total/duration          | 413      |\n| total/episodes          | 255      |\n| total/epochs            | 1        |\n| total/steps             | 179998   |\n| total/steps_per_second  | 435      |\n| train/loss_actor        | -25.4    |\n| train/loss_critic       | 3.69     |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 19       |\n| reference_Q_std         | 26.1     |\n| reference_action_mean   | 0.188    |\n| reference_action_std    | 0.929    |\n| reference_actor_Q_mean  | 20.2     |\n| reference_actor_Q_std   | 27.1     |\n| rollout/Q_mean          | 4.55     |\n| rollout/actions_mean    | 0.104    |\n| rollout/actions_std     | 0.662    |\n| rollout/episode_steps   | 588      |\n| rollout/episodes        | 323      |\n| rollout/return          | 28.4     |\n| rollout/return_history  | 79.5     |\n| total/duration          | 437      |\n| total/episodes          | 323      |\n| total/epochs            | 1        |\n| total/steps             | 189998   |\n| total/steps_per_second  | 435      |\n| train/loss_actor        | -49      |\n| train/loss_critic       | 1.98     |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\n--------------------------------------\n| reference_Q_mean        | 22.7     |\n| reference_Q_std         | 27.7     |\n| reference_action_mean   | -0.603   |\n| reference_action_std    | 0.773    |\n| reference_actor_Q_mean  | 23.9     |\n| reference_actor_Q_std   | 27.3     |\n| rollout/Q_mean          | 6.81     |\n| rollout/actions_mean    | 0.112    |\n| rollout/actions_std     | 0.672    |\n| rollout/episode_steps   | 470      |\n| rollout/episodes        | 425      |\n| rollout/return          | 43.8     |\n| rollout/return_history  | 92.6     |\n| total/duration          | 460      |\n| total/episodes          | 425      |\n| total/epochs            | 1        |\n| total/steps             | 199998   |\n| total/steps_per_second  | 435      |\n| train/loss_actor        | -52.7    |\n| train/loss_critic       | 1.9      |\n| train/param_noise_di... | 0        |\n--------------------------------------\n\nfinish!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\ndel model # remove to demonstrate saving and loading\\n\\nmodel = DDPG.load(\"ddpg_mountain\")\\n\\nobs = env.reset()\\nwhile True:\\n    action, _states = model.predict(obs)\\n    obs, rewards, dones, info = env.step(action)\\n    env.render()\\n    '"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#this is for DDPG-mountain\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.ddpg.policies import MlpPolicy\n",
    "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
    "from stable_baselines import DDPG\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "param_noise = None\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(MlpPolicy, env, verbose=1, param_noise=param_noise, action_noise=action_noise,memory_limit=5000,tensorboard_log='D:/DDPG_mountain_Logs')\n",
    "model.learn(total_timesteps=200000)\n",
    "#should be 30w steps\n",
    "model.save(\"ddpg_mountain\")\n",
    "from winsound import Beep\n",
    "Beep(3000, 500)\n",
    "print('finish!')\n",
    "'''\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpg_mountain\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#this is for DDPG-pendulum\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.ddpg.policies import MlpPolicy\n",
    "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
    "from stable_baselines import DDPG\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "\n",
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "param_noise = None\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(MlpPolicy, env, verbose=1, param_noise=param_noise, action_noise=action_noise,memory_limit=50000,tensorboard_log='D:/DDPG_pendulum_Logs')\n",
    "model.learn(total_timesteps=200000)\n",
    "model.save(\"ddpg_pendulum\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpg_pendulum\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#this is for SAC-pendulum\n",
    "#first experiment:gamma=0.99,0.95,0.90,0.85,1\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines import SAC\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,tensorboard_log='D:\\Logs',gamma=0.99, learning_rate=0.0003)\n",
    "model.learn(total_timesteps=30000, log_interval=10)\n",
    "#model.save(\"sac_noisypendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,tensorboard_log='D:\\Logs',gamma=0.99, learning_rate=0.001)\n",
    "model.learn(total_timesteps=30000, log_interval=10)\n",
    "#model.save(\"sac_noisypendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,tensorboard_log='D:\\Logs',gamma=0.99, learning_rate=0.003)\n",
    "model.learn(total_timesteps=30000, log_interval=10)\n",
    "#model.save(\"sac_noisypendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,tensorboard_log='D:\\Logs',gamma=0.99, learning_rate=0.0001)\n",
    "model.learn(total_timesteps=30000, log_interval=10)\n",
    "#model.save(\"sac_noisypendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,tensorboard_log='D:\\Logs',gamma=0.99, learning_rate=0.00003)\n",
    "model.learn(total_timesteps=30000, log_interval=10)\n",
    "#model.save(\"sac_noisypendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "print('finish!')\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "model = SAC.load(\"sac_noisypendulum\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "| qf1_loss                | 1.4110988e-06 |\n| qf2_loss                | 3.033584e-06  |\n| time_elapsed            | 253           |\n| total timesteps         | 86913         |\n| value_loss              | 3.278386e-06  |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015141951  |\n| ent_coef_loss           | 0.09416181    |\n| entropy                 | -1.0063857    |\n| episodes                | 92            |\n| fps                     | 342           |\n| mean 100 episode reward | -4.9          |\n| n_updates               | 90846         |\n| policy_loss             | 0.18577884    |\n| qf1_loss                | 5.0256614e-07 |\n| qf2_loss                | 4.4797164e-07 |\n| time_elapsed            | 265           |\n| total timesteps         | 90909         |\n| value_loss              | 1.0766794e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0014736172  |\n| ent_coef_loss           | -0.21643257   |\n| entropy                 | -1.0745783    |\n| episodes                | 96            |\n| fps                     | 339           |\n| mean 100 episode reward | -4.7          |\n| n_updates               | 94842         |\n| policy_loss             | 0.19429497    |\n| qf1_loss                | 1.2919244e-07 |\n| qf2_loss                | 1.8970184e-07 |\n| time_elapsed            | 279           |\n| total timesteps         | 94905         |\n| value_loss              | 1.5985361e-06 |\n-------------------------------------------\n--------------------------------------------\n| current_lr              | 0.0003         |\n| ent_coef                | 0.0014815731   |\n| ent_coef_loss           | 0.007251799    |\n| entropy                 | -1.0473869     |\n| episodes                | 100            |\n| fps                     | 337            |\n| mean 100 episode reward | -4.5           |\n| n_updates               | 98838          |\n| policy_loss             | 0.20054337     |\n| qf1_loss                | 1.6286037e-07  |\n| qf2_loss                | 1.08067056e-07 |\n| time_elapsed            | 293            |\n| total timesteps         | 98901          |\n| value_loss              | 1.2664594e-06  |\n--------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0014996802  |\n| ent_coef_loss           | -0.4343944    |\n| entropy                 | -0.9604435    |\n| episodes                | 104           |\n| fps                     | 335           |\n| mean 100 episode reward | -3.5          |\n| n_updates               | 102834        |\n| policy_loss             | 0.207         |\n| qf1_loss                | 1.1134016e-06 |\n| qf2_loss                | 1.0967964e-06 |\n| time_elapsed            | 306           |\n| total timesteps         | 102897        |\n| value_loss              | 3.5380203e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0014362939  |\n| ent_coef_loss           | 0.19517389    |\n| entropy                 | -1.0136341    |\n| episodes                | 108           |\n| fps                     | 335           |\n| mean 100 episode reward | -2.3          |\n| n_updates               | 106830        |\n| policy_loss             | 0.2081584     |\n| qf1_loss                | 9.2100487e-07 |\n| qf2_loss                | 7.422108e-07  |\n| time_elapsed            | 318           |\n| total timesteps         | 106893        |\n| value_loss              | 2.510557e-06  |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015060732  |\n| ent_coef_loss           | 0.5879807     |\n| entropy                 | -0.9333651    |\n| episodes                | 112           |\n| fps                     | 334           |\n| mean 100 episode reward | -1.5          |\n| n_updates               | 110826        |\n| policy_loss             | 0.21390998    |\n| qf1_loss                | 1.1101374e-06 |\n| qf2_loss                | 1.7330444e-06 |\n| time_elapsed            | 331           |\n| total timesteps         | 110889        |\n| value_loss              | 4.8649595e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0014759047  |\n| ent_coef_loss           | -0.2968062    |\n| entropy                 | -0.9516853    |\n| episodes                | 116           |\n| fps                     | 333           |\n| mean 100 episode reward | -1.1          |\n| n_updates               | 114822        |\n| policy_loss             | 0.21493094    |\n| qf1_loss                | 2.1433351e-07 |\n| qf2_loss                | 8.10179e-08   |\n| time_elapsed            | 343           |\n| total timesteps         | 114885        |\n| value_loss              | 9.440249e-07  |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015577492  |\n| ent_coef_loss           | 0.30501458    |\n| entropy                 | -1.0935748    |\n| episodes                | 120           |\n| fps                     | 333           |\n| mean 100 episode reward | -0.9          |\n| n_updates               | 118818        |\n| policy_loss             | 0.21928698    |\n| qf1_loss                | 6.4726876e-08 |\n| qf2_loss                | 1.1250539e-06 |\n| time_elapsed            | 355           |\n| total timesteps         | 118881        |\n| value_loss              | 3.6833521e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015178659  |\n| ent_coef_loss           | 0.37618065    |\n| entropy                 | -1.0399387    |\n| episodes                | 124           |\n| fps                     | 333           |\n| mean 100 episode reward | -0.9          |\n| n_updates               | 122814        |\n| policy_loss             | 0.22150561    |\n| qf1_loss                | 8.575756e-07  |\n| qf2_loss                | 1.2252754e-06 |\n| time_elapsed            | 368           |\n| total timesteps         | 122877        |\n| value_loss              | 1.7415903e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015782985  |\n| ent_coef_loss           | 0.432077      |\n| entropy                 | -0.9375974    |\n| episodes                | 128           |\n| fps                     | 333           |\n| mean 100 episode reward | -0.9          |\n| n_updates               | 126810        |\n| policy_loss             | 0.22903755    |\n| qf1_loss                | 2.8793975e-06 |\n| qf2_loss                | 2.8140694e-06 |\n| time_elapsed            | 380           |\n| total timesteps         | 126873        |\n| value_loss              | 1.1551979e-05 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015683589  |\n| ent_coef_loss           | -0.3964986    |\n| entropy                 | -0.9203505    |\n| episodes                | 132           |\n| fps                     | 331           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 130806        |\n| policy_loss             | 0.23100471    |\n| qf1_loss                | 0.00042272604 |\n| qf2_loss                | 0.00042258552 |\n| time_elapsed            | 394           |\n| total timesteps         | 130869        |\n| value_loss              | 1.6179189e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0014786992  |\n| ent_coef_loss           | -1.6504006    |\n| entropy                 | -0.88160306   |\n| episodes                | 136           |\n| fps                     | 331           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 134802        |\n| policy_loss             | 0.2304586     |\n| qf1_loss                | 4.301255e-06  |\n| qf2_loss                | 1.2940475e-06 |\n| time_elapsed            | 406           |\n| total timesteps         | 134865        |\n| value_loss              | 4.1346725e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0016162199  |\n| ent_coef_loss           | -0.15366188   |\n| entropy                 | -1.0402799    |\n| episodes                | 140           |\n| fps                     | 331           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 138798        |\n| policy_loss             | 0.23217961    |\n| qf1_loss                | 4.5599186e-06 |\n| qf2_loss                | 5.235071e-06  |\n| time_elapsed            | 418           |\n| total timesteps         | 138861        |\n| value_loss              | 1.43904e-05   |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015495918  |\n| ent_coef_loss           | 0.15406027    |\n| entropy                 | -1.0291904    |\n| episodes                | 144           |\n| fps                     | 331           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 142794        |\n| policy_loss             | 0.23594022    |\n| qf1_loss                | 3.9953886e-07 |\n| qf2_loss                | 7.808229e-07  |\n| time_elapsed            | 431           |\n| total timesteps         | 142857        |\n| value_loss              | 2.1562557e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015680956  |\n| ent_coef_loss           | -0.0632104    |\n| entropy                 | -1.0075821    |\n| episodes                | 148           |\n| fps                     | 331           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 146790        |\n| policy_loss             | 0.23509288    |\n| qf1_loss                | 2.6475955e-06 |\n| qf2_loss                | 2.4176977e-06 |\n| time_elapsed            | 443           |\n| total timesteps         | 146853        |\n| value_loss              | 2.9401613e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.001605726   |\n| ent_coef_loss           | 0.20569298    |\n| entropy                 | -0.96624506   |\n| episodes                | 152           |\n| fps                     | 331           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 150786        |\n| policy_loss             | 0.23688644    |\n| qf1_loss                | 0.00042997915 |\n| qf2_loss                | 0.00043053247 |\n| time_elapsed            | 455           |\n| total timesteps         | 150849        |\n| value_loss              | 3.9035986e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0016968097  |\n| ent_coef_loss           | -0.36097172   |\n| entropy                 | -1.0167046    |\n| episodes                | 156           |\n| fps                     | 331           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 154782        |\n| policy_loss             | 0.24010341    |\n| qf1_loss                | 1.7397022e-07 |\n| qf2_loss                | 7.7278645e-07 |\n| time_elapsed            | 467           |\n| total timesteps         | 154845        |\n| value_loss              | 2.2562003e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0016234465  |\n| ent_coef_loss           | 0.78605044    |\n| entropy                 | -1.0439509    |\n| episodes                | 160           |\n| fps                     | 331           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 158778        |\n| policy_loss             | 0.23760119    |\n| qf1_loss                | 3.650074e-06  |\n| qf2_loss                | 1.9118395e-06 |\n| time_elapsed            | 479           |\n| total timesteps         | 158841        |\n| value_loss              | 3.832098e-06  |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0016309642  |\n| ent_coef_loss           | -0.6184454    |\n| entropy                 | -0.9902967    |\n| episodes                | 164           |\n| fps                     | 331           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 162774        |\n| policy_loss             | 0.23897609    |\n| qf1_loss                | 5.548245e-07  |\n| qf2_loss                | 3.1078497e-07 |\n| time_elapsed            | 491           |\n| total timesteps         | 162837        |\n| value_loss              | 1.6140435e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015587338  |\n| ent_coef_loss           | 0.76520497    |\n| entropy                 | -0.96070266   |\n| episodes                | 168           |\n| fps                     | 331           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 166770        |\n| policy_loss             | 0.23969303    |\n| qf1_loss                | 5.631746e-08  |\n| qf2_loss                | 8.356665e-08  |\n| time_elapsed            | 503           |\n| total timesteps         | 166833        |\n| value_loss              | 2.9056417e-07 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0016060789  |\n| ent_coef_loss           | 0.2997043     |\n| entropy                 | -1.023493     |\n| episodes                | 172           |\n| fps                     | 330           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 170766        |\n| policy_loss             | 0.24225       |\n| qf1_loss                | 4.694578e-06  |\n| qf2_loss                | 4.3243444e-06 |\n| time_elapsed            | 516           |\n| total timesteps         | 170829        |\n| value_loss              | 2.0190153e-05 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015587783  |\n| ent_coef_loss           | -0.12499344   |\n| entropy                 | -0.9727185    |\n| episodes                | 176           |\n| fps                     | 330           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 174762        |\n| policy_loss             | 0.23724279    |\n| qf1_loss                | 2.8286643e-06 |\n| qf2_loss                | 3.0618892e-06 |\n| time_elapsed            | 528           |\n| total timesteps         | 174825        |\n| value_loss              | 5.6034546e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0016122658  |\n| ent_coef_loss           | -0.44886017   |\n| entropy                 | -0.9271223    |\n| episodes                | 180           |\n| fps                     | 330           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 178758        |\n| policy_loss             | 0.23856717    |\n| qf1_loss                | 2.4613934e-07 |\n| qf2_loss                | 3.2337874e-07 |\n| time_elapsed            | 541           |\n| total timesteps         | 178821        |\n| value_loss              | 1.2701761e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0016404338  |\n| ent_coef_loss           | -0.35274822   |\n| entropy                 | -0.93374026   |\n| episodes                | 184           |\n| fps                     | 329           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 182754        |\n| policy_loss             | 0.23819162    |\n| qf1_loss                | 5.538916e-08  |\n| qf2_loss                | 4.3685395e-07 |\n| time_elapsed            | 554           |\n| total timesteps         | 182817        |\n| value_loss              | 1.3425556e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015768941  |\n| ent_coef_loss           | 0.60076046    |\n| entropy                 | -0.999001     |\n| episodes                | 188           |\n| fps                     | 329           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 186750        |\n| policy_loss             | 0.23755461    |\n| qf1_loss                | 1.6635377e-06 |\n| qf2_loss                | 6.137309e-07  |\n| time_elapsed            | 566           |\n| total timesteps         | 186813        |\n| value_loss              | 1.0399674e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015832704  |\n| ent_coef_loss           | 0.79992384    |\n| entropy                 | -0.97560775   |\n| episodes                | 192           |\n| fps                     | 329           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 190746        |\n| policy_loss             | 0.24020086    |\n| qf1_loss                | 4.8586685e-08 |\n| qf2_loss                | 9.13449e-08   |\n| time_elapsed            | 578           |\n| total timesteps         | 190809        |\n| value_loss              | 6.7801386e-07 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.0015756035  |\n| ent_coef_loss           | -0.074715674  |\n| entropy                 | -0.94670063   |\n| episodes                | 196           |\n| fps                     | 329           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 194742        |\n| policy_loss             | 0.24181196    |\n| qf1_loss                | 0.000441555   |\n| qf2_loss                | 0.0004397574  |\n| time_elapsed            | 592           |\n| total timesteps         | 194805        |\n| value_loss              | 2.2255188e-06 |\n-------------------------------------------\n-------------------------------------------\n| current_lr              | 0.0003        |\n| ent_coef                | 0.00158261    |\n| ent_coef_loss           | 0.805236      |\n| entropy                 | -0.97654337   |\n| episodes                | 200           |\n| fps                     | 328           |\n| mean 100 episode reward | -0.8          |\n| n_updates               | 198738        |\n| policy_loss             | 0.24321863    |\n| qf1_loss                | 8.1445137e-07 |\n| qf2_loss                | 2.7316696e-07 |\n| time_elapsed            | 604           |\n| total timesteps         | 198801        |\n| value_loss              | 1.4722827e-06 |\n-------------------------------------------\nfinish!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\ndel model # remove to demonstrate saving and loading\\n\\nmodel = SAC.load(\"sac_noisymountaion\")\\n\\nobs = env.reset()\\nwhile True:\\n    action, _states = model.predict(obs)\\n    obs, rewards, dones, info = env.step(action)\\n    env.render()\\n    '"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "#this is for SAC-mountain\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines import SAC\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "model = SAC(MlpPolicy, env, verbose=1,learning_starts=0,learning_rate=0.0003,tensorboard_log='D:\\SAC_mountain_Logs')\n",
    "model.learn(total_timesteps=200000,)\n",
    "model.save(\"sac_noisymountaion\")\n",
    "from winsound import Beep\n",
    "Beep(3000, 500)\n",
    "print('finish!')\n",
    "\n",
    "'''\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = SAC.load(\"sac_noisymountaion\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#this is for four-compare\n",
    "#first experiment:gamma=0.99,0.95,0.90,0.85,1\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines import SAC, DDPG\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,gamma=0.99, learning_rate=0.0003)\n",
    "model.learn(total_timesteps=300000, log_interval=10)\n",
    "model.save(\"sac_pendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "model = SAC(MlpPolicy, env, verbose=1,learning_starts=0,learning_rate=0.0003,buffer_size=50000,batch_size=64,ent_coef='auto',train_freq=1,gradient_steps=1)\n",
    "model.learn(total_timesteps=300000, log_interval=10)\n",
    "model.save(\"sac_mountaincar\")\n",
    "del model \n",
    "del env\n",
    "\n",
    "from stable_baselines.ddpg.policies import MlpPolicy\n",
    "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "param_noise = None\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "model = DDPG(MlpPolicy, env, verbose=1, param_noise=param_noise, action_noise=action_noise,memory_limit=50000)\n",
    "model.learn(total_timesteps=300000)\n",
    "model.save(\"DDPG_pendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "param_noise = None\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "model = DDPG(MlpPolicy, env, verbose=1, param_noise=param_noise, action_noise=action_noise,memory_limit=5000)\n",
    "model.learn(total_timesteps=300000)\n",
    "model.save(\"DDPG_mountaincar\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env\n",
    "\n",
    "print('finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines import SAC, DDPG\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model = SAC(MlpPolicy, env, learning_starts=1000,tensorboard_log='D:\\Compare_4',gamma=0.99, learning_rate=0.0003)\n",
    "model.learn(total_timesteps=50000, log_interval=10)\n",
    "#model.save(\"sac_noisypendulum\")\n",
    "del model # remove to demonstrate saving and loading\n",
    "del env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#test well-trained model performance in common scenerio and noisy scenerio \n",
    "import gym\n",
    "import numpy as np\n",
    "from stable_baselines.ddpg.policies import MlpPolicy\n",
    "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
    "from stable_baselines import SAC, DDPG\n",
    "\n",
    "acn=[0,-0.2,-0.4,-0.6,-0.7,-0.8]\n",
    "obn=[0,0.04,0.08,0.12,0.15,0.18]\n",
    "\n",
    "env = gym.make('NoisyPendulum-v0')\n",
    "model=SAC.load(\"sac_pendulum\")\n",
    "obs = env.reset()\n",
    "\n",
    "SACpendu_reward=[]\n",
    "for dd in range(6):\n",
    "    env.set_noise(acn[dd],obn[dd])\n",
    "    obs = env.reset()\n",
    "    sub_reward=[]\n",
    "    for dd in range(400):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        sub_reward.append(rewards)\n",
    "    SACpendu_reward.append(sub_reward)\n",
    "SACpendu_total=np.array(SACpendu_reward)\n",
    "\n",
    "del model\n",
    "\n",
    "model=DDPG.load(\"ddpg_pendulum\")\n",
    "obs = env.reset()\n",
    "\n",
    "DDPGpendu_reward=[]\n",
    "for dd in range(5):\n",
    "    env.set_noise(acn[dd],obn[dd])\n",
    "    obs = env.reset()\n",
    "    sub_reward=[]\n",
    "    for dd in range(200):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        sub_reward.append(rewards)\n",
    "    DDPGpendu_reward.append(sub_reward)\n",
    "DDPGpendu_total=np.array(SACpendu_reward)\n",
    "\n",
    "print('finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw section-SAC\n",
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure()\n",
    "fig.suptitle(\"SAC vs mix noise\")\n",
    "\n",
    "sbp1=plt.subplot(2,3,1)\n",
    "plt.plot(range(400),SACpendu_total[0,:])\n",
    "sbp1.set_title(\"acn=0.0,obn=0\")\n",
    "\n",
    "sbp2=plt.subplot(2,3,2)\n",
    "plt.plot(range(400),SACpendu_total[1,:])\n",
    "sbp2.set_title(\"acn=-0.2,obn=0.08\")\n",
    "\n",
    "sbp3=plt.subplot(2,3,3)\n",
    "plt.plot(range(400),SACpendu_total[2,:])\n",
    "sbp3.set_title(\"acn=-0.4,obn=0.08\")\n",
    "\n",
    "sbp4=plt.subplot(2,3,4)\n",
    "plt.plot(range(400),SACpendu_total[3,:])\n",
    "sbp4.set_title(\"acn=-0.6,obn=0.12\")\n",
    "\n",
    "sbp5=plt.subplot(2,3,5)\n",
    "plt.plot(range(400),SACpendu_total[4,:])\n",
    "sbp5.set_title(\"acn=-0.7,obn=0.15\")\n",
    "\n",
    "sbp5=plt.subplot(2,3,6)\n",
    "plt.plot(range(400),SACpendu_total[5,:])\n",
    "sbp5.set_title(\"acn=-0.8,obn=0.18\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.6,wspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw section-DDPG\n",
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure()\n",
    "fig.suptitle(\"DDPG vs mix noise\")\n",
    "\n",
    "sbp1=plt.subplot(2,3,1)\n",
    "plt.plot(range(400),DDPGpendu_total[0,:])\n",
    "sbp1.set_title(\"acn=0.0,obn=0\")\n",
    "\n",
    "sbp2=plt.subplot(2,3,2)\n",
    "plt.plot(range(400),DDPGpendu_total[1,:])\n",
    "sbp2.set_title(\"acn=0.2,obn=0.04\")\n",
    "\n",
    "sbp3=plt.subplot(2,3,3)\n",
    "plt.plot(range(400),DDPGpendu_total[2,:])\n",
    "sbp3.set_title(\"acn=0.4,obn=0.08\")\n",
    "\n",
    "sbp4=plt.subplot(2,3,4)\n",
    "plt.plot(range(400),DDPGpendu_total[3,:])\n",
    "sbp4.set_title(\"acn=0.6,obn=0.12\")\n",
    "\n",
    "sbp5=plt.subplot(2,3,5)\n",
    "plt.plot(range(400),DDPGpendu_total[4,:])\n",
    "sbp5.set_title(\"acn=0.7,obn=0.15\")\n",
    "\n",
    "sbp5=plt.subplot(2,3,6)\n",
    "plt.plot(range(400),DDPGpendu_total[5,:])\n",
    "sbp5.set_title(\"acn=0.8,obn=0.18\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.6,wspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bit7a32da46385a4693b6171a0a1568aa93",
   "display_name": "Python 3.6.10 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}